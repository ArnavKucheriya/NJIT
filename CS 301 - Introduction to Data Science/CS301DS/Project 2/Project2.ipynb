{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Import Libraries\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv('StudentsPerformance.csv')\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Initial Exploration\n",
    "# -----------------------------\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Average Score Column (Optional Bonus)\n",
    "# -----------------------------\n",
    "df['average score'] = (df['math score'] + df['reading score'] + df['writing score']) / 3\n",
    "\n",
    "# -----------------------------\n",
    "# 5. EDA: Dataset Visualizations\n",
    "# -----------------------------\n",
    "\n",
    "# Distribution of categorical features\n",
    "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Distribution of numerical features\n",
    "numerical_cols = ['math score', 'reading score', 'writing score']\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap between scores\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Between Scores')\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for Gender distribution\n",
    "gender_counts = df['gender'].value_counts()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Gender Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of math score by gender\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(data=df, x='gender', y='math score')\n",
    "plt.title('Math Score by Gender')\n",
    "plt.show()\n",
    "\n",
    "# Violin plot of math score by test preparation course\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.violinplot(data=df, x='test preparation course', y='math score')\n",
    "plt.title('Math Score by Test Preparation Course')\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Preprocessing: Encoding Categorical Variables\n",
    "# -----------------------------\n",
    "features = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "target = 'math score'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le  # Save encoders\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train-Test Split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Model Training\n",
    "# -----------------------------\n",
    "\n",
    "# Model 1: Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Model 2: Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Predictions\n",
    "# -----------------------------\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "# Linear Regression\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Decision Tree\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "rmse_dt = np.sqrt(mse_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(f\"RMSE: {rmse_lr:.2f}\")\n",
    "print(f\"R² Score: {r2_lr:.2f}\\n\")\n",
    "\n",
    "print(\"Decision Tree Regressor Results:\")\n",
    "print(f\"RMSE: {rmse_dt:.2f}\")\n",
    "print(f\"R² Score: {r2_dt:.2f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Model Results Visualizations\n",
    "# -----------------------------\n",
    "\n",
    "# Actual vs Predicted - Linear Regression\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x=y_test, y=y_pred_lr)\n",
    "plt.title('Actual vs Predicted - Linear Regression')\n",
    "plt.xlabel('Actual Math Score')\n",
    "plt.ylabel('Predicted Math Score')\n",
    "plt.plot([0, 100], [0, 100], 'r--')\n",
    "plt.show()\n",
    "\n",
    "# Actual vs Predicted - Decision Tree\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x=y_test, y=y_pred_dt)\n",
    "plt.title('Actual vs Predicted - Decision Tree Regressor')\n",
    "plt.xlabel('Actual Math Score')\n",
    "plt.ylabel('Predicted Math Score')\n",
    "plt.plot([0, 100], [0, 100], 'r--')\n",
    "plt.show()\n",
    "\n",
    "# Residuals Distribution - Linear Regression\n",
    "residuals_lr = y_test - y_pred_lr\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(residuals_lr, bins=30, kde=True)\n",
    "plt.title('Residuals Distribution - Linear Regression')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Residuals Distribution - Decision Tree\n",
    "residuals_dt = y_test - y_pred_dt\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(residuals_dt, bins=30, kde=True)\n",
    "plt.title('Residuals Distribution - Decision Tree Regressor')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# RMSE Comparison\n",
    "models = ['Linear Regression', 'Decision Tree']\n",
    "rmse_values = [rmse_lr, rmse_dt]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=models, y=rmse_values)\n",
    "plt.title('Model RMSE Comparison')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "\n",
    "# R² Score Comparison\n",
    "r2_values = [r2_lr, r2_dt]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=models, y=r2_values)\n",
    "plt.title('Model R² Score Comparison')\n",
    "plt.ylabel('R² Score')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
