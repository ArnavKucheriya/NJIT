{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7172bfb3",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Introduction to decision trees\n",
    "\n",
    "A **decision tree** is a set of questions that check if a condition is met and flow from one into the other to make a decision. Depending on the answer, further questions are asked to narrow down possible outcomes and arrive at a decision. A decision tree is typically depicted as an upside down tree. The parts of a decision tree are:\n",
    "\n",
    "- **Decision node:** where a feature of the data is tested.\n",
    "- **Root node:** the first decision node in the tree.\n",
    "- **Branch:** a connection between decision nodes in the tree.\n",
    "- **Layer:** all of the decision nodes that are the same distance from the root node.\n",
    "- **Leaf node:** a node that does not test a feature and so is where a decision is made.\n",
    "- **Depth:** the number of layers in a decision tree.\n",
    "\n",
    "A **binary decision tree** is a decision tree in which each node has two branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aae9ec",
   "metadata": {},
   "source": [
    "### Classification trees\n",
    "\n",
    "A classification tree is a decision tree used for classifying an object or event into a categorical feature. Classification is the most common use of decision trees. For classification trees, the leaves represent the class of a new instance. Ex: A bank classifies transactions into \"fraudulent\" or \"non fraudulent\"; a mobile advertiser decides whether to send a phone user an advertisement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002ea9e",
   "metadata": {},
   "source": [
    "| ![Simple Decision Tree](An-example-of-a-simple-decision-tree.png) |\n",
    "|:--:|\n",
    "| <b>Source: https://online.visual-paradigm.com/knowledge/decision-tree/what-is-decision-tree/</b>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedeaa1d",
   "metadata": {},
   "source": [
    "1. This decision tree determines whether or not to purchase a car. The first question, \"Is the car red?\", is the root node.\n",
    "2. The two possible answers are yes or no. Each answer is a branch on the decision tree.\n",
    "3. If the answer is no, we come to another decision point. \"Is the color yellow?\" has two possible answers.  If the answer is no, we come to the 'Don't Buy\" node - a leaf node.\n",
    "4. If the car is red, then model year is examined at a decision node.\n",
    "5. If the model year is newer than 2010, then the car should be purchased. Otherwise, there is another decision point regarding odometer miles before a leaf node is reached and a decision made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b05d52",
   "metadata": {},
   "source": [
    "### Introduction to regression trees\n",
    "\n",
    "A regression tree is a model to predict a numerical value from a decision tree. A regression tree is built by dividing a feature into regions and finding the mean of each region. Generally, a regression tree model performs better than a linear regression model when the relationship is not clearly linear. Ex: The price of a car with respect to its age, and the expected value of a basketball shot based on its distance. But, cross validation techniques should always be used to compare model performance for any regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db64e8f",
   "metadata": {},
   "source": [
    "| ![Decision Tree Regression](DecisionTreeRegression.png) |\n",
    "|:--:|\n",
    "| <b>Source: **Data Science Foundations with Python with zyLabs**</b>|\n",
    "\n",
    "1. The regression tree first considers the house's number of bedrooms. If the house has one bedroom, the tree suggests \\\\$120 per square foot for the house's price.\n",
    "2. If the house has two or more bedrooms, the tree checks the number of bathrooms. If two or more bathrooms exist, the tree suggests a price of $210 per square foot.\n",
    "3. If there is only one bathroom, the number of parking spaces is used to estimate the price for a house.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db888723",
   "metadata": {},
   "source": [
    "**Advantages of a regression tree over linear regression.**\n",
    "\n",
    "| Linear regression\t| Regression tree |\n",
    "| :---------------- | :-------------- |\n",
    "| Fits linear data better\t| Has more flexibility with non-linear data\n",
    "| Missing values are discarded\t| Missing values can be converted to a separate class\n",
    "| Heavily affected by outliers\t| Not affected by outliers\n",
    "| Difficult to interpret graphically when the model has many features\t| Easy to interpret even when the model has many features\n",
    "| Statistical significance of each feature can be measured easily\t| Determining the importance of each feature is not straightforward |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38d11b",
   "metadata": {},
   "source": [
    "### Classification and Regression Trees (CART) algorithm\n",
    "\n",
    "**Classification and Regression Tree algorithm (CART)** is a method used to build trees by repeatedly splitting data with a threshold into two regions. A **threshold** is a numerical value that divides a feature into two parts: values above the threshold and below. A regression tree using CART is obtained by finding the nodes and branches that minimize the **residual sums of squares (RSS)** and consequently, **mean squared error (MSE)**, at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e722a9",
   "metadata": {},
   "source": [
    "**CART algorithm for regression.**\n",
    "\n",
    "For each decision node:\n",
    "\n",
    "Step 1: Select one of the features, $ x $.\n",
    "\n",
    "Step 2: Divide the training data into two regions, $ R_1 $ and $ R_2 $, by setting a threshold for $ x $ to split the data or choosing a particular value of $ x $ if $ x $ is categorical.\n",
    "\n",
    "Step 3: Calculate RSS where the predicted values $ \\hat{y}_i $ are the average of the observed values $ y_i $ within each region.\n",
    "\n",
    "Step 4: Repeat steps 2 and 3 for each possible threshold or particular value.\n",
    "\n",
    "Step 5: Repeat steps 1-4 for each possible feature.\n",
    "\n",
    "Step 6: The feature and threshold/particular value with the lowest RSS are selected to split the training set at the node. Splitting stops according to a pre-set criterion such as having a minimum number of instances in a leaf or a maximum number of terminal nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
