{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22ebf8d",
   "metadata": {},
   "source": [
    "# Data Preprocessing Steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c47a0",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db10320",
   "metadata": {},
   "source": [
    "## Import and examine the dataset\n",
    "- Do we have any missing values?\n",
    "- Show the dataframe sorted by State\n",
    "- Show the means of numeric features by State\n",
    "- Compute the min, max and mean of Salary and Age by state\n",
    "\n",
    "Use a many cells as needed to show your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee50ac8",
   "metadata": {},
   "source": [
    "[Dataset.csv](https://drive.google.com/file/d/1Sq7OQ-jMWFlF6Zamz5_RmIvjUt9d1THb/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (Ensure 'Dataset.csv' is in the same directory)\n",
    "file_path = \"Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bcbbb",
   "metadata": {},
   "source": [
    "## Take Care of missing data\n",
    "1.  Delete rows with missing data, or\n",
    "2.  Replace missing data with mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display dataset after removing missing values\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a513817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using mean strategy\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Select only numeric columns for imputation (avoid categorical columns)\n",
    "numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Verify no missing values remain\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d2b3d",
   "metadata": {},
   "source": [
    "## Encode Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac945004",
   "metadata": {},
   "source": [
    "#### Encode and display the categorical Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
    "\n",
    "# Assuming the first column contains categorical data\n",
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, 0] = labelencoder.fit_transform(df.iloc[:, 0])\n",
    "\n",
    "# Display the encoded dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73f319",
   "metadata": {},
   "source": [
    "#### Encode and display the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3722c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the dependent variable (last column)\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "\n",
    "# Display dataset with encoded dependent variable\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb710f",
   "metadata": {},
   "source": [
    "## Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting dataset into features and target variable\n",
    "X = df.iloc[:, :-1].values  # Assuming last column is target\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dataset shapes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1a6a4",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01891c8a",
   "metadata": {},
   "source": [
    "#### Standardized Scaling\n",
    "* Scale the numerical features using standardized scaling\n",
    "* Show your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Applying Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "# Display scaled dataset\n",
    "X_train_standardized[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e9fe6",
   "metadata": {},
   "source": [
    "#### Normalized Scaling\n",
    "* Scale the numerical features using normalized scaling\n",
    "* Show your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Applying Normalization\n",
    "normalizer = MinMaxScaler()\n",
    "X_train_normalized = normalizer.fit_transform(X_train)\n",
    "X_test_normalized = normalizer.transform(X_test)\n",
    "\n",
    "# Display normalized dataset\n",
    "X_train_normalized[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e3b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS301DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
